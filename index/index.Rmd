---
title: "PoissonERM: METHODS"
output:
  html_document: default
  pdf_document: default
---

## Introduction
This document shows the methods implemented in the package-like tool `PoissonERM`. Each auto-generated html report from `PoissonERM` contains the user's modeling options, and this document is a detailed supplement explaining the model selections and variable selections.

To install the package, go to https://github.com/yuchenw2015/PoissonERM.

The examples of using this tool are here: https://github.com/yuchenw2015/PoissonERM-Example.

## Modeling: Software and Strategy
The E-R analyses, data processing, and generation of figures and tables are performed in R programming language.The Poisson regression analyses are performed using the glm() function.

The analyses for each endpoint follow the below steps: 

  - Univariate models are estimated to compare and select the best exposure metric, if any. The model only contains exposure metric is the base model.
  - Predicted cumulative incidence rate from the base model are created in form of figures and tables if requested by user. 
   - If covariates are evaluated, then a full covariate model is estimated with the selected best exposure, if any, along with all covariates specified by the user.
  - If covariates are to be evaluated, then a backwards elimination procedure is run to determine a final model.  
  - The final model including covariates is estimated. 
  - Risk Ratio figures and tables are created if any demographic covariates are included in the final model.
  -	If requested, simulations are performed using the final model.

The E-R analysis is performed for each endpoints when the number of events meet the threshold (user choice).

## Poisson Distribuion and Binomial Distribution

Poisson regression modeling of the rate of an event occurrence for the population in a given time interval is a development based on the asymptotic convergence of a Binomial distribution with a rate $\pi$ and a large number of times the event is tested When the count of the events follow a Binomial distribution where 

$$Y \sim Binomial(t, \pi)$$

where, in this case, $t$ is some unit of time and $\pi$ is the constant rate of the event over time. When $t$ is large and $\pi$ is small (rare event), the distribution can be approximated as 
$$Y \sim Poisson(\lambda)$$
where $\lambda=t\pi$ and $\lambda$ is the mean count of the event in the given time interval. Then, the event rate can be modeled using Poisson regression with the following linearization 
$$log(\lambda_i)=log(t_i)+log(\pi_i)$$
where $log(t_i)$ is modeled as an offset in the model. 

`PoissonERM` is designed to conduct this type of analysis where the offset for time is built into the linearization of the model. The full analysis can be conducted for multiple endpoints with the models developed separately for each endpoint. This section describes the methodology behind the automated statistical analysis via `PoissonERM` and several key options that requires userâ€™s input.


## Base Model Description
In the base model, user-specified exposure metrics are tested as predictors for the occurrence of an event. 

The linear, square-root-transformed, and log-transformed scales of exposure metrics were investigated. Since the main purpose of the E-R analysis was to identify potential relationships between endpoints and exposure metrics, the endpoint was only explored and was not part of the main analysis conclusions if no exposure metric was defined.

The counts of events are assumed to be characterizable using a Poisson regression. The linear form of the regression is defined as a function of the mean (event rate). The base model includes an intercept and potential exposure metric as

\begin{equation}
\label{eqn:mod_1}
\text{log}(\frac{\lambda}{t_j}) = \beta_{0}+\beta_{1}\cdot \text{Exposure}_j
\end{equation}

which is equivalent to  

\begin{equation}
\label{eqn:mod}
\text{log}(\lambda) = \beta_{0}+\text{log}\left(t_{j}\right)+\beta_{1}\cdot \text{Exposure}_j
\end{equation}

where $\lambda$ is the mean count in a given time interval, $\beta_{0}$ is the mean count when the time interval, $t$, is equal to zero, $\text{log}\left(t_{j}\right)$ is the time-interval offset (days), $\text{Exposure}_j$ is the time-weighted Exposure at the time of AE driving the response in mean count, $\beta_{1}$ is the estimable effect of exposure on the mean count.

When assessing each exposure metric individually in the base model, the difference in the number of identifiable parameters (and therefore the $df$) is equal to 1. Decision making during model building was guided by evaluation of change in deviance, or $-2\cdot${log-likelihood}, between models. The Deviance (DEV) was calculated as:
\newline
\begin{equation}
\label{eqn:dev}
D=-2\log\left(\frac{L_0}{L_F}\right)
\end{equation}

where $L_0/L_F$ is the ratio of the likelihood of the null and fitted models. $D$ can be shown to be approximately $\chi^2$ distributed with degrees of freedom equal to the difference in the number of parameters estimated between the null and fitted models.

Based on user's input, exposure metric selection is done in one of the following ways:

  - The exposure metric met the significant level (p_val) is selected for the base model for each endpoint analyzed. If there are more than one metric that met the criteria, the metric with the smallest $p$-value is selected. If there is no metric that meets the criteria, the base model will not contain any exposure metric. 
   - The exposure metric with the largest change in deviance $\Delta D$ is selected for the base model for each endpoint analyzed, regardless of statistical significance.

The generated report includes the details of user's choice for each threshold or criteria.

## Random Effects Model Development
Since the Poisson regressions used only one measurement per subject, estimation of random effects is not possible.

## Inclusion of Covariates and Full Model Development
Both categorical and continuous covariates are tested for inclusion using a linear parameterization in the poisson regressions.

The covariate parameter structure that was used for categorical and continuous covariates is described below:
    -Linear parameterization for a categorical covariate x:
\begin{equation}
\text{COV} = 1; \text{most common}\\
\theta=\theta_0 \cdot \text{COV}
\end{equation}

where $\theta_0$ denotes the population value of the parameter for the reference demographic characteristic. The parameter $\theta$ represents the change in the intercept when compared to the reference characteristic. 
    -Linear parameterization for continuous covariates
\begin{equation}
\theta=\theta_0 \cdot (\text{COV}-\text{reference})
\end{equation}

where $\theta_0$ denotes the population value conditional on the value of the covariate, which changes linearly as a function of COV, reference value is usually the observed median value or given by user. Continuous covariates might be explored in the logarithmic scale and were tested in the models in the scale where the covariate follows a normal distribution.

If the user set `con.model.ref = "No"` to not use reference value in continuous covariates parameterization, $\text{reference} = 0$.

Categorical covariate will be dropped in full model development if all events occurred in only one of its categories. 
If any of the covariates are highly correlated (e.g. AST and ALT) with a correlation coefficient $\ge0.6$, then only one of the correlated covariates is tested further based on univariate DEV. 
The $\chi^2$ test for the log-likelihood difference in deviance between models is used to judge whether one model has a better fit over another during the backward elimination using an $\alpha$ (p_val_b) provided by user. When the removal of any of the remaining covariates results in a $\Delta D$ equivalent to p-value less than the $\alpha$ provided by user, the elimination process is stopped and the model was considered final.

## Missing Data
Missing data within covariates is imputed provided the percentage of missing values is $\le p.icon$ for continuous covariates and $\le p.icat$ for categorical covariates. $p.icon$ and $p.icat$ are provided by user. For continuous covariates, the median value is used for the imputed value. For categorical covariates, the mode is used for the imputed value. If the percentage of missing values is larger than the stated threshold, the covariates are excluded from consideration for the endpoint.

## Full Model Development
To assess the E-R relationship between potential covariates and each of the endpoints, a poisson regression model is used as: 

\begin{equation}
\label{eqn:LRbasecov_1}
\text{log}(\frac{\lambda}{t_j}) = \beta_{0} + \beta_1\cdot\text{Exposure}_j + \beta_2\cdot X_2 + \cdots + \beta_n\cdot X_n
\end{equation}

which is equivalent to 

\begin{equation}
\label{eqn:LRbasecov}
\text{log}(\lambda) = \beta_{0} + \text{log}\left(t_{j}\right) + \beta_1\cdot\text{Exposure}_j + \beta_2\cdot X_2 + \cdots + \beta_n\cdot X_n
\end{equation}

where $\lambda$ is the arithmetic mean of the counts occurring during a certain time interval, $\beta_0$ is the estimated intercept, $\beta_1$ is a regression coefficient (slope) representing the effect of the exposure metric, if any, based on base model development, and $\beta_2,\ldots,\beta_n$ represent the effect, if any, of each additional covariate on the log-odds of the event occurring.

## Final Model Development
Final model development starts with the full model, containing the parameters from the base model and any additional covariates under consideration. The full model is then subjected to a stepwise backwards elimination procedure, outlined below. 

To compare two nested models, the difference in the deviance of each of the models also follows an approximately $\chi^2$ distribution with degrees of freedom equal to the difference in the number of estimated parameters:

\begin{equation}
\label{eqn:nest}
\left(\frac{D_{nested}-D_{full}}{df_{nested}-df_{full}}\right)\sim\chi^2_{df_{nested}-df_{full}}
\end{equation}

where $df_{nested}$ and $df_{full}$ are the degree of freedom for the nested and full models, respectively.
